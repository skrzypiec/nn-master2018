\documentclass[]{article}
\usepackage{mathtools}
\usepackage[pdftex]{graphicx}	
\usepackage{amsmath,amsfonts,amsthm}	
\usepackage{tikz}
\usepackage{listings}
\usepackage{slashbox}
\usetikzlibrary{chains, positioning}
\newtheorem{theorem}{Theorem}[section]
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{corollary}[theorem]{Corollary}
\usepackage{sidecap}
\usepackage{polski}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\theoremstyle{definition}
\newtheorem{definition}{Definition}[section]
\usepackage{caption} 
\captionsetup[table]{skip=10pt}


\lstset{
	language=Python, %% Troque para PHP, C, Java, etc... bash é o padrão
	basicstyle=\ttfamily\small,
	numberstyle=\footnotesize,
	%numbers=left,
	%backgroundcolor=\color{gray!10},
	frame=single,
	tabsize=2,
	rulecolor=\color{black!30},
	title=\lstname,
	escapeinside={\%*}{*)},
	breaklines=true,
	breakatwhitespace=true,
	framextopmargin=2pt,
	framexbottommargin=2pt,
	inputencoding=utf8,
	extendedchars=true,
	literate={ą}{{\k a}}1 {ę}{{\k e}}1,} %{ś}{{\'s}}1,

\usetikzlibrary{calc,arrows}

%opening
%\title{Keras}
\author{Rafa\l \vspace{1cm} Skrzypiec}
%\date{}
\begin{document}
%\maketitle

%\section{Keras}
{\large Rafał Skrzypiec - Analiza}
\vspace{1cm}

\section{Walidacja krzyżowa}

Algorytm wykorzystywany podczas nauki modelu ma za zadnianie znalezienie takich parametrów, które sprawiają, że model odwzorowuje dane wykorzystane do nauki w sposób jak najlepszy z możliwych. Jeśli do walidacji modelu wykorzystamy inną, niezależną próbkę danych pochodzącą z tego samego zbioru co podzbiór uczący, zazwyczaj okaże się, że model nie działa aż tak dobrze jak przy użyciu zbioru uczącego. Rozmiar tej różnicy zwiększa się, szczególnie wtedy gdy wielkość zbioru treningowego jest niewielka, lub gdy liczba parametrów modelu jest bardzo duża.
Walidacja krzyżowa to metoda statystyczna, która ma za zadanie zminimalizować tę różnicę przez co pomaga ocenić i zwiększyć trafność przewidywań modelu predykcyjnego. 


W najprostszym przykładzie walidacji krzyżowej zbiór danych dzieli się na dwa podzbiory: uczący i walidacyjny. Podczas gdy zbiór uczący służy do nauki modelu, zbiór walidacyjny wykorzystuje się aby mierzyć błąd modelu na nieznanym zbiorze danych. 
		
W algorytmie $k$-krotnej walidacji krzyżowej zbiór danych jest losowo dzielony na $k$ równych wielkością podzbiorów. Jeden z $k$ podzbiorów jest przeznaczany na zbiór walidacyjny, pozostałe $k-1$ podzbiorów służą jako dane teningowe. Powyżej opisana procedura jest powtarzana $k$ razy, a każdy $k$ podzbiorów dokładnie raz zostaje wykorzystany jako zbiór testowy. Następnie $k$ wyników modelu jest uśrednianych dając w rezultacie jeden wynik. \figurename{} \ref{fig:cross-val} przedstawia sposób działania $10$-krotnej walidacji krzyżowej.

	\begin{figure}[htp!]
		\centering
		\includegraphics[width=1\textwidth]{cross_val.png}
		\caption{Na podstawie [Python Machine Learning
			Book by Sebastian Raschka]}
		\label{fig:cross-val}
	\end{figure}

\section{Wczesne zatrzymanie}
Algorytmy uczenia maszynowego dopasowują parametry modelu na podstawie danych treningowych o skończonym rozmiarze. Podczas procesu szkolenia model jest oceniany na podstawie tego, jak dobrze przewiduje obserwacje zawarte w tym zbiorze. Jednak celem uczenia maszynowego jest stworzenie modelu, który ma zdolność do przewidywania uprzednio niewidzianych obserwacji. Nadmierne dopasowanie to zjawisko pojawiające się wtedy gdy model za bardzo dopasowuje się do danych w zbiorze uczącym co powoduje zmniejszenie wartości błędu na tym zbiorze lecz równocześnie jest przyczyną wzrostu błędu na zbiorze testowym. Nadmierne dopasowanie modelu to problem, który może się pojawiać gdy model zawiera więcej parametrów niż wymagałaby tego natura modelowanego zjawiska. Sieć neuronowa to struktura skłonna do przeuczania. Podczas gdy obserwowany błąd obliczany w oparciu o dane treningowe spada, w pewnym momencie wartość błędu dla zbioru walidacyjnego zaczyna wzrastać. \figurename{} \ref{fig:loss_curves} przedstawia często zamieszczane w literaturze, wyidealizowane krzywe zmiany wartości funkcji straty w czasie, dla zbiorów treningowego i walidacyjnego. Najlepszy model predykcyjny miałby parametry, które odpowiadają momentowi globalnego minimum dla zbioru walidacyjnego.




\begin{figure}[htp!]
	\centering
	\includegraphics[width=1\textwidth]{early_stopping14_8.png}
	\caption{}
	\label{fig:loss_curves}
\end{figure}

W dziedzinie uczenia maszynowego, metoda wczesnego zatrzymania to forma regularyzacji, która pozwala uniknąć problemu przeuczenia, zatrzymując naukę modelu gdy wartość funkcji straty na zbiorze walidacyjnym zaczyna wzrastać. Rzeczywisty przebieg wartości funkcji straty ma wiele lokalnych minimów, dlatego na podstawie obserwacji krzywych uczenia dokonano wyboru kryteriów zatrzymania nauki modelu. 
 Niech $\Theta_{wa}(t)$ to wartość funkcji straty na zbiorze walidacyjnym po $t$ epokach, $\Theta_{min}(t)$ to dotychczasowe minimum funkcji straty na zbiorze walidacyjnym po $t$ epokach, definiowane jako:
 $$
 \Theta_{min}(t) \equiv \min_{t' < t} \Theta_{wa}(t')
 $$
 
 Niech $\Theta_{sr}(t)$ będzię średnią wartością funkcji straty dla zbioru walidacyjnego z ostatnich 10 epok.
 
 $$
 \Theta_{sr}(t) \equiv \frac{1}{10} \sum_{i=0}^{10} \Theta_{wa}(t-i)
 $$
 
 Oraz zdefiniujmy pomocniczy parametr $GL(t)$
 
 
 $$
 GL(t) \equiv \frac{\Theta_{sr}(t)}{\Theta_{min}} - 1
 $$
 
 
 Podczas nauki przedstawioneg modelu, do wczesnego zatrzymania wystarczyło spełnienie jednego z dwóch obowiązujących warunków:

\begin{itemize}
\item $\Theta_{min}(t) = \Theta_{min}(t+ 200)$ dla wszystkich $t \in [t,t+200]$, brak zmniejszenia minimalnej wartości funkcji straty dla zbioru walidacyjnego przez 200 epok 
\item $ GL(t)  > 2$, względny wzrost średniej wartości funkcji straty przez ostatnie 10 epok względem osiągniętego minimum jest większy niż $200\%$
\end{itemize}

Po skończeniu nauki, wybierany jest model, który ma najmniejszą wartość funkcji straty na zbiorze testowym.

\section{Ilość neuronów}

Architektura sieci neuronowej, tzn. ilość warstw ukrytych oraz ilość neuronów w warstwach ukrytych jest zdeterminowana przez wymiar danych wejściowych, rodzaj rozwiązywanego problemu (klasyfikacja czy regresja) oraz relację między zmiennymi objaśniającymi i zmienną objaśnianą.

Uogólniony model liniowy przydatny w szerokim zakresie zastosowań, nie potrzebuję żadnej warstwy ukrytej. Bywa szczególnie przydatny gdy zbiór zawiera mało danych lub są one obarczone dużą niedokładnością. Nawet w przypadku gdy relacja między zmiennymi jest lekko nieliniowa, użycie prostego modelu liniowego może skutkować lepszym uogólnieniem problemu niż skomplikowany model będący wrażliwy na każdy szum znajdujący się w danych. Zgodnie z uniwersalnym twierdzeniem aproksymacyjnym jedna warstwa ukryta z wystarczająco dużą liczbą neuronów wystarcza aby z dowolną dokładnością dowolną ciągłą funkcję [cybenko]. Jeśli zmienna objaśniająca jest jednowymiarowa, wydaje się, że nie odniesiemy żadnej korzyści z skonstruowania sieci neuronowej o więcej niż jednej warstwie ukrytej. Sprawy komplikują się jednak gdy zmienna wejściowa jest dwu lub więcej wymiarowa. Dwuwarstowa sieć neuronowa zachowuje właściwości jednowarstwowej sieci neuronowej oraz osiąga zdolność nauki każdego problemu klasyfikacyjnego [1995 Bishop 123], ponadto wielowarstwowa sieć neuronowa z dwoma warstwami może skutkować dokładniejszymi wynikami wykorzystując mniejszą ilość parametrów niż jednowarstwowa sieć [Chester (1990)].

Na tej podstawie, do rozwiązania problemu regresji gdzie wejściem jest para liczb $(\varepsilon, Q^2)$ postanowiłem wybrać sieć neuronowa z dwoma warstwami ukrytymi. 


\begin{table}
\centering

\caption{Liczba parametrów sieci neuonowej z dwoma warstwami ukrytymi w zależności od liczby neuronów w warstwach}\label{tab:title} 


\begin{tabular}{c|p{1cm}|p{1cm}|p{1cm}|p{1cm}}
	\backslashbox{I warstwa}{II warstwa} & 2 & 3 & 4 & 5\\\hline\hline
	2 & 14 & 18 & 22 & 26 \\ \hline
		3 & 19 & 24 & 29 & 34 \\ \hline
			4 & 24 & 30 & 36 & 42 \\ \hline
				5 & 29 & 36 & 43 & 50 \\ \hline
\end{tabular}
\end{table}

%opisać liczbę parametrów + poniższy obrazek

\begin{figure}[htp!]
	\centering
	\includegraphics[width=1\textwidth]{neuronyy14_8.png}
	\caption{Opis}
	\label{fig:neurony}
\end{figure}


\begin{figure}	
\centering
	
	\begin{tikzpicture}
	[   cnode/.style={draw=black,draw=black,fill=#1,minimum width=8mm,circle},
	]
	\tikzset{normal arrow/.style={draw,-latex}}
	\node[cnode=white,label=0:Wyjście] (s) at (9,-7) {};
	
	\node[cnode=white,label=180:Bias] (x-3) at (0,-9) {1};

	
	\node[cnode=white,label=180:] (p-4) at (3,-10) {$1$};
	
	\node[cnode=white,label=180:] (z-6) at (6,-12) {$1$};	
	
	
	\node[cnode=white,label=180:$\varepsilon$] (x-1) at (0,-5) {};
	\node[cnode=white,label=180:$Q^2$] (x-2) at (0,-7) {};

	\node[cnode=white,label=180:] (p-1) at (3,-4) {};
	\node[cnode=white,label=180:] (p-2) at (3,-6) {};
	\node[cnode=white,label=180:] (p-3) at (3,-8) {};
	
	\node[cnode=white,label=180:] (z-1) at (6,-2) {};
	\node[cnode=white,label=180:] (z-2) at (6,-4) {};
	\node[cnode=white,label=180:] (z-3) at (6,-6) {};
	\node[cnode=white,label=180:] (z-4) at (6,-8) {};
	\node[cnode=white,label=180:] (z-5) at (6,-10) {};
	


	\foreach \x in {1,...,6}
	{
		\path[normal arrow] (z-\x) -- node[above,sloped,pos=0.4] {} (s);
	}
	
	
	\foreach \x in {1,...,3}
	{   
		\foreach \y in {1,...,3}
		{   

			\path[normal arrow] (x-\x) -- (p-\y); 				
		}
	}

	\foreach \x in {1,...,4}
	{   
	\foreach \y in {1,...,5}
	{   
		
		\path[normal arrow] (p-\x) -- (z-\y); 
	}
	
	
	
	\ifnum \x=5
	\path[normal arrow] (z-\x) -- node[above,sloped,pos=0.4] {} (s);
	\else
	
	\fi
	}

\end{tikzpicture}
\caption{Schemat zastosowanej sieci neuronowej, która składa się z: i) warstwy wejściowej z dwoma neuronami, ii) dwóch warstw ukrytych z odpowiednio trzema i pięcioma neuronami, iii) warstwy wyjściowej z jednym neuronem. Linie zakończone strzałką oznaczają wagę odpowiadającą każdej z par neuronów. } \label{tab:scheme} 	
\end{figure}


\end{document}


	
http://page.mi.fu-berlin.de/prechelt/Biblio/stop_tricks1997.pdf